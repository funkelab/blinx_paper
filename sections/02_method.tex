\section{Method}

\subsection{Model}

Consider a complex smaller than the fluorescence spatial resolution limit,
consisting of \n individually labeled subunits.

Each subunit is labeled such that it stochastically fluoresces over time,
independently of the others, resulting in $\y{t} \in [0, \n]$ fluorophores
illuminated at any given timepoint $t$, producing a fluorescent signal of
intensity \x{t}. We can then estimate \n, from an observed intensity sequence
$\trace = (\x{1},\ldots,\x{T})$ through maximum likelihood estimation.

\begin{equation}
  \estimatedn =
    \argmax{\n}
    \max_\parameters
    p(\trace|\n,\parameters)
  \text{,}
\end{equation}
%
where \parameters are parameters of the model that we will introduce below.

Assuming that each state \y{t} depends only on the previous state \y{t-1}, this process can be modeled as a hidden Markov model. Expanding to include $\states = \left( \y{1}, \ldots, \y{T} \right)$:

\begin{equation}
  p(\trace|\n,\parameters) =
    \sum_{\states}
    p_\parameters(\x{1}|\y{1}) p_\parameters(\y{1}|\n)
    \prod_{t=2}^{T}
    p_\parameters(\x{t}|\y{t}) p_\parameters(\y{t}|\y{t-1},\n)
\end{equation}

The emission distribution $p(\x{t}|\y{t})$ describes the relationship
between the observations \trace, and the hidden state \states, and can be
approximated by a log-normal distribution (??), \ie,
%
\begin{equation}
  p(\x{t}|\y{t}) =
    \frac{1}{\x{t}\sigma\sqrt{2\pi}}
    \exp \left(
      - \frac{|\log(\x{t}) - \y{t}\mu|^2}{2\sigma^2}
    \right)
  \text{,}
\end{equation}
%
where $\mu$ and $\sigma$ are the mean and standard deviation of the intensity
of a single activated emitter.

The transition distribution $p(\y{t}|\y{t-1},\n)$ describes the kinetics of
arriving at any hidden state \y{t} from any other hidden state \y{t-1}. The
probability of a single subunit which is dark at time $t-1$ illuminating at
time $t$ is defined as \pon. Conversely, the probability of a single subunit
which is active at time $t-1$ going dark at time $t$ can be defined as \poff.
Assuming that each emitter behaves independently, and that all share a common
\pon and \poff, the transition probability between any two states can be
written as:

Equation from oneNote

%Specifically for DNA-PAINT experiments, \pon and \poff can be defined, through the exponential distribution, in terms of the rate constants k_on and k_off often used to describe DNA binding and dissociation.

%P_on = exposure_time * k_on * exp(-exposure_time * k_on)
%P_off = exposure_time * k_off * exp(-exposure_time * k_off)

Altogether, the probability of observing trace \trace can be written as a
function of five parameters: $p(\trace|\n,\parameters)$

\subsection{Inference}

\todo{mention: no closed form solution to estimate \parameters}
\todo{solution: gradient ascent on \parameters}

The model was fit using gradient ascent to find the optimal combination of these 5 parameters to maximize the likelihood of observing intensity trace X. While pon, poff, mu and sigma are continuous, N is discrete and therefore not differentiable. Fortunately, the sample space for possible N values is relatively small ( ~ 50) and it is possible to independently fit a model for each N, then take a maximum over likelihoods to find the optimal N. 
Before fitting for each given N, a rough grid search was used to determine initial guesses for each of the parameters. In the case of multiple local maxima, all were used to initiate gradient ascent rather than just the global maxima to reduce the risk of finding false summits. The likelihood p(X | pon, poff, mu, sigma) was calculated using the forward algorithm and the gradient of this function on all 4 parameters was calculated using JAX. Parameters were then optimized using stochastic gradient ascent.
One challenge is that for long observation sequences the likelihood of any consecutive observation sequence becomes vanishingly small, and numerically unstable. To alleviate this effect, all probabilities were computed in log space which results in summation, rather than multiplication of consecutive probabilities, reducing the small number problem. Additionally, the probabilities for each timepoint were normalized to sum to 1, and later re-converted to further reduce this issue. JAX was used to vectorize almost the entire fitting process allowing the quick calculation of gradients and the fitting of many traces in parallel. 
